{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IZrAitlFLdEZ"
   },
   "source": [
    "# Welcome to MNIST with keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "jSmUsjJfMEqC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras : version 2.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -q -U keras\n",
    "\n",
    "import keras\n",
    "\n",
    "print('keras : version {}'.format(keras.__version__))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B8Lhscw0NDln"
   },
   "source": [
    "### Step 1: Download the dataset\n",
    "\n",
    "The MNIST dataset contains thousands of grayscale images of handwritten digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "FKiwTuT-NE6f"
   },
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train_images` and `train_labels` form the \"training set\", the data that the model will learn from. The model will then be tested on the \n",
    "\"test set\", `test_images` and `test_labels`. Our images are encoded as Numpy arrays, and the labels are simply an array of digits, ranging \n",
    "from 0 to 9. There is a one-to-one correspondence between the images and the labels.\n",
    "\n",
    "## Step 1a: Have a look at your data\n",
    "Let's have a look at the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "i = random.randint(0, 100)\n",
    "\n",
    "plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Eo_cZXaqODnZ"
   },
   "source": [
    "### Step 2) Prepare your data\n",
    "Before training, we will preprocess our data by reshaping it into the shape that the network expects, and scaling it so that all values are in \n",
    "the `[0, 1]` interval. Previously, our training images for instance were stored in an array of shape `(60000, 28, 28)` of type `uint8` with \n",
    "values in the `[0, 255]` interval. We transform it into a `float32` array of shape `(60000, 28 * 28)` with values between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "OgnV5FJjP5Vz"
   },
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GI25z0StQH-P"
   },
   "source": [
    "Next, we want to convert the labels from an integer format (e.g., \"2\"), to a [one hot encoding](https://en.wikipedia.org/wiki/One-hot) (e.g., \"0, 0, 1, 0, 0, 0, 0, 0, 0, 0\"). To do so, we'll use the `keras.utils.to_categorical` [function](https://keras.io/utils/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "E9yrkEENQ9Vz"
   },
   "outputs": [],
   "source": [
    "train_labels = keras.utils.to_categorical(train_labels)\n",
    "test_labels = keras.utils.to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pjdbemHURkpv"
   },
   "source": [
    "### Step 3) Build the model\n",
    "\n",
    "Now, we'll create our neural network using the [Keras Sequential API](https://keras.io/models/sequential/). \n",
    "* Architecture wise, we'll single layer network. \n",
    "* The hidden layer will have 512 units using the [ReLU](https://keras.io/activations#relu) activation function. \n",
    "* The output layer will have 10 units and use [softmax](https://keras.io/activations#softmax) function. \n",
    "* Notice, we specify the input shape on the first layer. If you add subsequent layers, this is not necessary. \n",
    "* We will use the [categorical crossentropy](https://keras.io/losses#categorical_crossentropy) loss function, and the [RMSProp](https://keras.io/optimizers#rmsprop) optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "mNscbvHkUrMc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# We will now compile and print out a summary of our model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k3br9Yi6VuBT"
   },
   "source": [
    "### Step 4) Training\n",
    "\n",
    "Next, we will train the model by using the [fit method](https://keras.io/models/model#fit) for 5 [epochs](https://www.quora.com/What-is-epochs-in-machine-learning). We will keep track of the training loss and accuracy as we go. This step may take a while depending on your hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "gBs0LwqcVXx6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.2576 - acc: 0.9253\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1045 - acc: 0.9684\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.0689 - acc: 0.9794\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 4s 58us/step - loss: 0.0507 - acc: 0.9851\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0377 - acc: 0.9886\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10c298d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rcYMPkwkWIPq"
   },
   "source": [
    "### Step 5) Testing\n",
    "Now that we have trained our model, we want to evaluate it. Sure, our model is >97% accurate on the training set, but what about on data it hasn't seen before? The test accuracy is a good metric for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "iuqDe4NiWBpU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 31us/step\n",
      "Test accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy: %.2f' % (accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jo-yoMwvXkw6"
   },
   "source": [
    "## Congratulations\n",
    "You have successfully used Keras to train a model on the MNIST dataset."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "1-mnist-with-keras.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
